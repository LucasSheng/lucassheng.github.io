@article{sheng_visibility_2019,
 abstract = {In this paper, we propose a generative framework that unifies depth-based 3D facial pose tracking and face model adaptation on-the-fly, in the unconstrained scenarios with heavy occlusions and arbitrary facial expression variations. Specifically, we introduce a statistical 3D morphable model that flexibly describes the distribution of points on the surface of the face model, with an efficient switchable online adaptation that gradually captures the identity of the tracked subject and rapidly constructs a suitable face model when the subject changes. Moreover, unlike prior art that employed ICP-based facial pose estimation, to improve robustness to occlusions, we propose a ray visibility constraint that regularizes the pose based on the face model's visibility with respect to the input point cloud. Ablation studies and experimental results on Biwi and ICT-3DHP datasets demonstrate that the proposed framework is effective and outperforms completing state-of-the-art depth-based methods.},
 author = {Sheng, Lu and Cai, Jianfei and Cham, Tat-Jen and Pavlovic, Vladimir and Ngan, King Ngi},
 doi = {10.1109/TPAMI.2018.2877675},
 file = {IEEE Xplore Abstract Record:/Users/lucasjing/Zotero/storage/MCUUSL5I/8502935.html:text/html;Submitted Version:/Users/lucasjing/Zotero/storage/8H9Q5A2V/Sheng et al. - 2019 - Visibility Constrained Generative Model for Depth-.pdf:application/pdf},
 issn = {1939-3539},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 keywords = {Three-dimensional displays, 3D facial pose tracking, Adaptation models, depth, Face, generative model, mixture of Gaussian models, online Bayesian model, Pose estimation, Shape, Solid modeling, Switches},
 note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
 number = {8},
 pages = {1994--2007},
 title = {Visibility Constrained Generative Model for Depth-Based 3D Facial Pose Tracking},
 volume = {41},
 year = {2019}
}

