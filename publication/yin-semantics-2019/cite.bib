@inproceedings{yin_semantics_2019,
 abstract = {Synthesizing photo-realistic images from text descriptions is a challenging problem. Previous studies have shown remarkable progresses on visual quality of the generated images. In this paper, we consider semantics from the input text descriptions in helping render photo-realistic images. However, diverse linguistic expressions pose challenges in extracting consistent semantics even they depict the same thing. To this end, we propose a novel photo-realistic text-to-image generation model that implicitly disentangles semantics to both fulfill the high-level semantic consistency and low-level semantic diversity. To be specific, we design (1) a Siamese mechanism in the discriminator to learn consistent high-level semantics, and (2) a visual-semantic embedding strategy by semantic-conditioned batch normalization to find diverse low-level semantics. Extensive experiments and ablation studies on CUB and MS-COCO datasets demonstrate the superiority of the proposed method in comparison to state-of-the-art methods.},
 author = {Yin, Guojun and Liu, Bin and Sheng, Lu and Yu, Nenghai and Wang, Xiaogang and Shao, Jing},
 booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
 doi = {10.1109/CVPR.2019.00243},
 file = {IEEE Xplore Abstract Record:/Users/lucasjing/Zotero/storage/F7SEVDTT/8953563.html:text/html;Yin et al. - Semantics Disentangling for Text-To-Image Generati.pdf:/Users/lucasjing/Zotero/storage/85LFTAGI/Yin et al. - Semantics Disentangling for Text-To-Image Generati.pdf:application/pdf},
 keywords = {Image and Video Synthesis, Vision + Language},
 month = {June},
 note = {ISSN: 2575-7075},
 pages = {2322--2331},
 title = {Semantics Disentangling for Text-To-Image Generation},
 year = {2019}
}

