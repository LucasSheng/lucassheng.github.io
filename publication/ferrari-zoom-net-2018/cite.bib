@incollection{ferrari_zoom-net_2018,
 abstract = {Recognizing visual relationships subject-predicate-object among any pair of localized objects is pivotal for image understanding. Previous studies have shown remarkable progress in exploiting linguistic priors or external textual information to improve the performance. In this work, we investigate an orthogonal perspective based on feature interactions. We show that by encouraging deep message propagation and interactions between local object features and global predicate features, one can achieve compelling performance in recognizing complex relationships without using any linguistic priors. To this end, we present two new pooling cells to encourage feature interactions: (i) Contrastive ROI Pooling Cell, which has a unique deROI pooling that inversely pools local object features to the corresponding area of global predicate features. (ii) Pyramid ROI Pooling Cell, which broadcasts global predicate features to reinforce local object features. The two cells constitute a Spatiality-Context-Appearance Module (SCA-M), which can be further stacked consecutively to form our ﬁnal Zoom-Net. We further shed light on how one could resolve ambiguous and noisy object and predicate annotations by Intra-Hierarchical trees (IH-tree). Extensive experiments conducted on Visual Genome dataset demonstrate the eﬀectiveness of our feature-oriented approach compared to state-of-the-art methods (Acc@1 11.42% from 8.16%) that depend on explicit modeling of linguistic interactions. We further show that SCA-M can be incorporated seamlessly into existing approaches to improve the performance by a large margin.},
 address = {Cham},
 author = {Yin, Guojun and Sheng, Lu and Liu, Bin and Yu, Nenghai and Wang, Xiaogang and Shao, Jing and Loy, Chen Change},
 booktitle = {Computer Vision – ECCV 2018},
 doi = {10.1007/978-3-030-01219-9_20},
 editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
 file = {Yin et al. - 2018 - Zoom-Net Mining Deep Feature Interactions for Vis.pdf:/Users/lucasjing/Zotero/storage/5B8D377A/Yin et al. - 2018 - Zoom-Net Mining Deep Feature Interactions for Vis.pdf:application/pdf},
 isbn = {978-3-030-01218-2 978-3-030-01219-9},
 language = {en},
 note = {Series Title: Lecture Notes in Computer Science},
 pages = {330--347},
 publisher = {Springer International Publishing},
 shorttitle = {Zoom-Net},
 title = {Zoom-Net: Mining Deep Feature Interactions for Visual Relationship Recognition},
 url = {http://link.springer.com/10.1007/978-3-030-01219-9_20},
 urldate = {2022-08-22},
 volume = {11207},
 year = {2018}
}

