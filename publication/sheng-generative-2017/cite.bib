@inproceedings{sheng_generative_2017,
 abstract = {We consider the problem of depth-based robust 3D facial pose tracking under unconstrained scenarios with heavy occlusions and arbitrary facial expression variations. Unlike the previous depth-based discriminative or data-driven methods that require sophisticated training or manual intervention, we propose a generative framework that uniﬁes pose tracking and face model adaptation on-the-ﬂy. Particularly, we propose a statistical 3D face model that owns the ﬂexibility to generate and predict the distribution and uncertainty underlying the face model. Moreover, unlike prior arts employing the ICP-based facial pose estimation, we propose a ray visibility constraint that regularizes the pose based on the face model’s visibility against the input point cloud, which augments the robustness against the occlusions. The experimental results on Biwi and ICT-3DHP datasets reveal that the proposed framework is effective and outperforms the state-of-the-art depth-based methods.},
 address = {Honolulu, HI},
 author = {Sheng, Lu and Cai, Jianfei and Cham, Tat-Jen and Pavlovic, Vladimir and Ngan, King Ngi},
 booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 doi = {10.1109/CVPR.2017.489},
 file = {Sheng et al. - 2017 - A Generative Model for Depth-Based Robust 3D Facia.pdf:/Users/lucasjing/Zotero/storage/QCJS64EV/Sheng et al. - 2017 - A Generative Model for Depth-Based Robust 3D Facia.pdf:application/pdf},
 isbn = {978-1-5386-0457-1},
 language = {en},
 month = {July},
 pages = {4598--4607},
 publisher = {IEEE},
 title = {A Generative Model for Depth-Based Robust 3D Facial Pose Tracking},
 url = {http://ieeexplore.ieee.org/document/8099972/},
 urldate = {2022-08-22},
 year = {2017}
}

