<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.6.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Lu Sheng" />

  
  
  
    
  
  <meta name="description" content="" />

  
  <link rel="alternate" hreflang="en-us" href="https://lucassheng.github.io/project/3d-perception-and-modeling/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.e16b071c3437dd38fe4bc6049c3c2fff.css" />

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



  


  


  




  
  
  

  
  

  
  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://lucassheng.github.io/project/3d-perception-and-modeling/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Lu Sheng (盛律)" />
  <meta property="og:url" content="https://lucassheng.github.io/project/3d-perception-and-modeling/" />
  <meta property="og:title" content="3D Perception and Modeling | Lu Sheng (盛律)" />
  <meta property="og:description" content="" /><meta property="og:image" content="https://lucassheng.github.io/project/3d-perception-and-modeling/featured.png" />
    <meta property="twitter:image" content="https://lucassheng.github.io/project/3d-perception-and-modeling/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-09-05T13:30:40&#43;08:00"
      />
    
    <meta property="article:modified_time" content="2022-09-05T13:30:40&#43;08:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lucassheng.github.io/project/3d-perception-and-modeling/"
  },
  "headline": "3D Perception and Modeling",
  
  "image": [
    "https://lucassheng.github.io/project/3d-perception-and-modeling/featured.png"
  ],
  
  "datePublished": "2022-09-05T13:30:40+08:00",
  "dateModified": "2022-09-05T13:30:40+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Lu Sheng"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Lu Sheng (盛律)",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lucassheng.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": ""
}
</script>

  

  

  


  <title>3D Perception and Modeling | Lu Sheng (盛律)</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="45bdd89c240e8069860e112bac34f54f" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.613040fe4f2c0f007b4dcb64404201cb.js"></script>

  




  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Lu Sheng (盛律)</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Lu Sheng (盛律)</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#news"><span>News</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article article-project">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>3D Perception and Modeling</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Sep 5, 2022
  </span>
  

  

  

  
  
  
  

  
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      
    </div>

    







<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://lucassheng.github.io/project/3d-perception-and-modeling/&amp;text=3D%20Perception%20and%20Modeling" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://lucassheng.github.io/project/3d-perception-and-modeling/&amp;t=3D%20Perception%20and%20Modeling" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=3D%20Perception%20and%20Modeling&amp;body=https://lucassheng.github.io/project/3d-perception-and-modeling/" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://lucassheng.github.io/project/3d-perception-and-modeling/&amp;title=3D%20Perception%20and%20Modeling" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=3D%20Perception%20and%20Modeling%20https://lucassheng.github.io/project/3d-perception-and-modeling/" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://lucassheng.github.io/project/3d-perception-and-modeling/&amp;title=3D%20Perception%20and%20Modeling" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://lucassheng.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu9bd0e58d2495c46038200f34e1c10f03_7252684_270x270_fill_q75_lanczos_center.jpg" alt="Lu Sheng"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://lucassheng.github.io/">Lu Sheng</a></h5>
      <h6 class="card-subtitle">Associate Professor</h6>
      <p class="card-text">Associate Professor at the School of Software, Beihang University, China.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com.hk/citations?user=_8lB7xcAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/LucasSheng" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/uploads/lsheng_resume_20220708.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


















    <div class="project-related-pages content-widget-hr">
      
      

      
      
      

      
      
      
        <h2>Publications</h2>
        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/gao-sketchsampler-2022/" >SketchSampler: Sketch-based 3D Reconstruction via View-dependent Depth Sampling</a>
    </div>

    
    <a href="/publication/gao-sketchsampler-2022/"  class="summary-link">
      <div class="article-style">
        Reconstructing a 3D shape based on a single sketch image is challenging due to the large domain gap between a sparse, irregular sketch …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Chenjian Gao</span>, <span >
      Qian Yu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Yi-Zhe Song</span>, <span >
      Dong Xu</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2208.06880v1.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/gao-sketchsampler-2022/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/liu-votehmr-2021/" >VoteHMR: Occlusion-Aware Voting Network for Robust 3D Human Mesh Recovery from Partial Point Clouds</a>
    </div>

    
    <a href="/publication/liu-votehmr-2021/"  class="summary-link">
      <div class="article-style">
        Accepted by ACM Multimedia 2021, as <strong>Oral presentation</strong>.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Guanze Liu</span>, <span >
      Yu Rong</span>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2110.08729" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/liu-votehmr-2021/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/hanabi7/VoteHMR" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1145/3474085.3475309" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/liu-votehmr-2021/" >
      <img src="/publication/liu-votehmr-2021/featured_huec59b68e617aec066cc1b88f3b8c49cd_378463_150x0_resize_q75_h2_lanczos_3.webp" height="35" width="150"
           alt="VoteHMR: Occlusion-Aware Voting Network for Robust 3D Human Mesh Recovery from Partial Point Clouds" loading="lazy">
    </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/zhao-transformer-3d-det-2021/" >Transformer3D-Det: Improving 3D Object Detection by Vote Refinement</a>
    </div>

    
    <a href="/publication/zhao-transformer-3d-det-2021/"  class="summary-link">
      <div class="article-style">
        Voting-based methods (e.g., VoteNet) have achieved promising results for 3D object detection. However, the simple voting operation in …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Lichen Zhao</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Jinyang Guo,</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Dong Xu</span>, <span class="author-highlighted">
      Lu Sheng</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/zhao-transformer-3d-det-2021/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/TCSVT.2021.3102025" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/cheng-back-tracing-2021/" >Back-tracing Representative Points for Voting-based 3D Object Detection in Point Clouds</a>
    </div>

    
    <a href="/publication/cheng-back-tracing-2021/"  class="summary-link">
      <div class="article-style">
        Accepted by CVPR 2021. A lightweight model with SOTA results on ScanNet V2 and SUN RGB-D datasets.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Bowen Cheng</span>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Shaoshuai Shi</span>, <span >
      Ming Yang</span>, <span >
      Dong Xu</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Back-Tracing_Representative_Points_for_Voting-Based_3D_Object_Detection_in_Point_CVPR_2021_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/cheng-back-tracing-2021/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/cheng052/BRNet" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR46437.2021.00885" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://paperswithcode.com/paper/back-tracing-representative-points-for-voting" target="_blank" rel="noopener">
    <i class="fab fa-hackerrank mr-1"></i>Ranks in Papers with Code</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/cheng-back-tracing-2021/" >
      <img src="/publication/cheng-back-tracing-2021/featured_hu326f05796d4a4dd6350e00a1c3e5cf36_233411_150x0_resize_q75_h2_lanczos_3.webp" height="65" width="150"
           alt="Back-tracing Representative Points for Voting-based 3D Object Detection in Point Clouds" loading="lazy">
    </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/dong-bags-2019/" >Bags of tricks for learning depth and camera motion from monocular videos</a>
    </div>

    
    <a href="/publication/dong-bags-2019/"  class="summary-link">
      <div class="article-style">
        <ul>
<li><em>Background</em>: Based on the seminal work proposed by Zhou et al., much of the recent progress in learning monocular visual odometry, i. …</li></ul>
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Bowen Dong</span>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/dong-bags-2019/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1016/j.vrih.2019.09.004" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sheng-unsupervised-2019/" >Unsupervised Collaborative Learning of Keyframe Detection and Visual Odometry Towards Monocular Deep SLAM</a>
    </div>

    
    <a href="/publication/sheng-unsupervised-2019/"  class="summary-link">
      <div class="article-style">
        In this paper we tackle the joint learning problem of keyframe detection and visual odometry towards monocular visual SLAM systems. As …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Dan Xu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Wanli Ouyang</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Sheng_Unsupervised_Collaborative_Learning_of_Keyframe_Detection_and_Visual_Odometry_Towards_ICCV_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sheng-unsupervised-2019/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ICCV.2019.00440" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/sheng-unsupervised-2019/" >
      <img src="/publication/sheng-unsupervised-2019/featured_huc169a33371988cef23233c7506b1d752_189339_150x0_resize_q75_h2_lanczos_3.webp" height="96" width="150"
           alt="Unsupervised Collaborative Learning of Keyframe Detection and Visual Odometry Towards Monocular Deep SLAM" loading="lazy">
    </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/wu-cascaded-2019/" >Cascaded regression using landmark displacement for 3D face reconstruction</a>
    </div>

    
    <a href="/publication/wu-cascaded-2019/"  class="summary-link">
      <div class="article-style">
        This paper proposes a novel model fitting algorithm for 3D facial expression reconstruction from a single image. Face expression …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Fanzi Wu</span>, <span >
      Songnan Li</span>, <span >
      Tianhao Zhao</span>, <span >
      King Ngi Ngan</span>, <span class="author-highlighted">
      Lu Sheng</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/wu-cascaded-2019/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1016/j.patrec.2019.07.017" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/li-gs-3-d-2019/" >GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving</a>
    </div>

    
    <a href="/publication/li-gs-3-d-2019/"  class="summary-link">
      <div class="article-style">
        We present an efﬁcient 3D object detection framework based on a single RGB image in the scenario of autonomous driving. Our efforts are …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Buyu Li</span>, <span >
      Wanli Ouyang</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Xingyu Zeng</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_GS3D_An_Efficient_3D_Object_Detection_Framework_for_Autonomous_Driving_CVPR_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/li-gs-3-d-2019/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2019.00111" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/li-gs-3-d-2019/" >
      <img src="/publication/li-gs-3-d-2019/featured_hufa95f52956de6f1dda8a4171a3713296_200559_150x0_resize_q75_h2_lanczos_3.webp" height="25" width="150"
           alt="GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving" loading="lazy">
    </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sheng-visibility-2019/" >Visibility Constrained Generative Model for Depth-Based 3D Facial Pose Tracking</a>
    </div>

    
    <a href="/publication/sheng-visibility-2019/"  class="summary-link">
      <div class="article-style">
        In this paper, we propose a generative framework that unifies depth-based 3D facial pose tracking and face model adaptation on-the-fly, …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Jianfei Cai</span>, <span >
      Tat-Jen Cham</span>, <span >
      Vladimir Pavlovic</span>, <span >
      King Ngi Ngan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sheng-visibility-2019/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/TPAMI.2018.2877675" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/sheng-visibility-2019/" >
      <img src="/publication/sheng-visibility-2019/featured_huc216e1f4a0717a9740050890457f241a_1451485_150x0_resize_q75_h2_lanczos_3.webp" height="62" width="150"
           alt="Visibility Constrained Generative Model for Depth-Based 3D Facial Pose Tracking" loading="lazy">
    </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sheng-generative-2017/" >A Generative Model for Depth-Based Robust 3D Facial Pose Tracking</a>
    </div>

    
    <a href="/publication/sheng-generative-2017/"  class="summary-link">
      <div class="article-style">
        We consider the problem of depth-based robust 3D facial pose tracking under unconstrained scenarios with heavy occlusions and arbitrary …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Jianfei Cai</span>, <span >
      Tat-Jen Cham</span>, <span >
      Vladimir Pavlovic</span>, <span >
      King Ngi Ngan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Sheng_A_Generative_Model_CVPR_2017_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sheng-generative-2017/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2017.489" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/sheng-generative-2017/" >
      <img src="/publication/sheng-generative-2017/featured_hu0fcdffd010b5226e8ea87e348fee16e8_83762_150x0_resize_q75_h2_lanczos.webp" height="84" width="150"
           alt="A Generative Model for Depth-Based Robust 3D Facial Pose Tracking" loading="lazy">
    </a>
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/li-real-time-2016/" >Real-Time Head Pose Tracking with Online Face Template Reconstruction</a>
    </div>

    
    <a href="/publication/li-real-time-2016/"  class="summary-link">
      <div class="article-style">
        We propose a real-time method to accurately track the human head pose in the 3-dimensional (3D) world. Using a RGB-Depth camera, a face …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Songnan Li</span>, <span >
      King Ngi Ngan</span>, <span >
      Raveendran Paramesran</span>, <span class="author-highlighted">
      Lu Sheng</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/li-real-time-2016/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/TPAMI.2015.2500221" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

        
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/li-head-2013/" >A Head Pose Tracking System Using RGB-D Camera</a>
    </div>

    
    <a href="/publication/li-head-2013/"  class="summary-link">
      <div class="article-style">
        In this paper, a fast head pose tracking system is introduced. It uses iterative closest point algorithm to register a dense face …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Songnan Li</span>, <span >
      King Ngi Ngan</span>, <span class="author-highlighted">
      Lu Sheng</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/li-head-2013/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-642-39402-7_16" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

        
      

      
      
      
    </div>
  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  

  

  

  
  






  
  <p class="powered-by copyright-license-text">
    © 2022 Lu Sheng. Last updated Aug 30, 2022.
  </p>
  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.46271ef31da3f018e9cd1b59300aa265.js"></script>




  

  
  

  






























<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js" type="module"></script>









<script src="/en/js/wowchemy.min.6ae253cfe39dce6eae1aa243112736e8.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>
















</body>
</html>
