<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.6.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Lu Sheng" />

  
  
  
    
  
  <meta name="description" content="Associate Professor" />

  
  <link rel="alternate" hreflang="en-us" href="https://lucassheng.github.io/publication-type/1/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.e16b071c3437dd38fe4bc6049c3c2fff.css" />

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



  


  


  




  
  
  

  
  
    <link rel="alternate" href="/publication-type/1/index.xml" type="application/rss+xml" title="Lu Sheng (盛律)" />
  

  
  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://lucassheng.github.io/publication-type/1/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Lu Sheng (盛律)" />
  <meta property="og:url" content="https://lucassheng.github.io/publication-type/1/" />
  <meta property="og:title" content="1 | Lu Sheng (盛律)" />
  <meta property="og:description" content="Associate Professor" /><meta property="og:image" content="https://lucassheng.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://lucassheng.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="og:updated_time" content="2022-10-23T00:00:00&#43;00:00" />
    
  

  



  


  <title>1 | Lu Sheng (盛律)</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.613040fe4f2c0f007b4dcb64404201cb.js"></script>

  




  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Lu Sheng (盛律)</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Lu Sheng (盛律)</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#news"><span>News</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    












  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>1</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/pan-video-2019/" >Video Generation From Single Semantic Label Map</a>
    </div>

    
    <a href="/publication/pan-video-2019/"  class="summary-link">
      <div class="article-style">
        This paper proposes the novel task of video generation conditioned on a SINGLE semantic label map, which provides a good balance …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Junting Pan</span>, <span >
      Chengyu Wang</span>, <span >
      Xu Jia</span>, <span >
      Jing Shao</span>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Junjie Yan</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Pan_Video_Generation_From_Single_Semantic_Label_Map_CVPR_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/pan-video-2019/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/junting/seg2vid" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/image-and-video-synthesis/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2019.00385" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/pan-video-2019/" >
      <img src="/publication/pan-video-2019/featured_hub3b7f782e6b32268900a8a4a24e923af_205742_150x0_resize_q75_h2_lanczos_3.webp" height="60" width="150"
           alt="Video Generation From Single Semantic Label Map" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/liu-multi-label-2018/" >Multi-Label Image Classification via Knowledge Distillation from Weakly-Supervised Detection</a>
    </div>

    
    <a href="/publication/liu-multi-label-2018/"  class="summary-link">
      <div class="article-style">
        Multi-label image classification is a fundamental but challenging task towards general visual understanding. Existing methods found the …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Yongcheng Liu</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Jing Shao</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Junjie Yan</span>, <span >
      Shiming Xiang</span>, <span >
      Chunhong Pan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1809.05884" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/liu-multi-label-2018/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/Yochengliu/MLIC-KD-WSD" target="_blank" rel="noopener">
  Code
</a>




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://yochengliu.github.io/MLIC-KD-WSD/" target="_blank" rel="noopener">
  Project
</a>









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1145/3240508.3240567" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/liu-multi-label-2018/" >
      <img src="/publication/liu-multi-label-2018/featured_hua89c7567e98392ac76f6ae0b6a8322d2_2686908_150x0_resize_q75_h2_lanczos.webp" height="93" width="150"
           alt="Multi-Label Image Classification via Knowledge Distillation from Weakly-Supervised Detection" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/ferrari-zoom-net-2018/" >Zoom-Net: Mining Deep Feature Interactions for Visual Relationship Recognition</a>
    </div>

    
    <a href="/publication/ferrari-zoom-net-2018/"  class="summary-link">
      <div class="article-style">
        Recognizing visual relationships subject-predicate-object among any pair of localized objects is pivotal for image understanding. …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Guojun Yin</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Bin Liu</span>, <span >
      Nenghai Yu</span>, <span >
      Xiaogang Wang</span>, <span >
      Jing Shao</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Chen Change Loy</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Guojun_Yin_Zoom-Net_Mining_Deep_ECCV_2018_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/ferrari-zoom-net-2018/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/gjyin91/ZoomNet" target="_blank" rel="noopener">
  Code
</a>




  
    
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-030-01219-9_20" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/ferrari-zoom-net-2018/" >
      <img src="/publication/ferrari-zoom-net-2018/featured_hu4a07fd64afe4e95e04ce4a4d754e0847_69044_150x0_resize_q75_h2_lanczos.webp" height="76" width="150"
           alt="Zoom-Net: Mining Deep Feature Interactions for Visual Relationship Recognition" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sheng-avatar-net-2018/" >Avatar-Net: Multi-scale Zero-Shot Style Transfer by Feature Decoration</a>
    </div>

    
    <a href="/publication/sheng-avatar-net-2018/"  class="summary-link">
      <div class="article-style">
        Zero-shot artistic style transfer is an important image synthesis problem aiming at transferring arbitrary style into content images. …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Ziyi Lin</span>, <span >
      Jing Shao</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sheng-avatar-net-2018/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/LucasSheng/avatar-net" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/image-and-video-synthesis/">
    Project
  </a>
  







  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=amaeqbw6TeA" target="_blank" rel="noopener">
  Video
</a>



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2018.00860" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/sheng-avatar-net-2018/" >
      <img src="/publication/sheng-avatar-net-2018/featured_hucf0b9fe5017668894548d770c0583df7_1005999_150x0_resize_q75_h2_lanczos_3.webp" height="33" width="150"
           alt="Avatar-Net: Multi-scale Zero-Shot Style Transfer by Feature Decoration" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/liu-exploring-2018/" >Exploring Disentangled Feature Representation Beyond Face Identification</a>
    </div>

    
    <a href="/publication/liu-exploring-2018/"  class="summary-link">
      <div class="article-style">
        This paper proposes learning disentangled but complementary face features with a minimal supervision by face identiﬁcation. …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Yu Liu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Fangyin Wei</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Jing Shao</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Junjie Yan</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Exploring_Disentangled_Feature_CVPR_2018_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/liu-exploring-2018/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/image-and-video-synthesis/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2018.00222" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/liu-exploring-2018/" >
      <img src="/publication/liu-exploring-2018/featured_huca880c2106f7385e22abf5b993ddad72_526278_150x0_resize_q75_h2_lanczos_3.webp" height="158" width="150"
           alt="Exploring Disentangled Feature Representation Beyond Face Identification" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sun-optical-2018/" >Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition</a>
    </div>

    
    <a href="/publication/sun-optical-2018/"  class="summary-link">
      <div class="article-style">
        Motion representation plays a vital role in human action recognition in videos. In this study, we introduce a novel compact motion …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Shuyang Sun</span>, <span >
      Zhanghui Kuang</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Wanli Ouyang</span>, <span >
      Wei Zhang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Optical_Flow_Guided_CVPR_2018_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sun-optical-2018/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kevin-ssy/Optical-Flow-Guided-Feature" target="_blank" rel="noopener">
  Code
</a>




  
    
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2018.00151" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/sun-optical-2018/" >
      <img src="/publication/sun-optical-2018/featured_hub099b7059c0f19b5068497a08653ace0_35031_150x0_resize_q75_h2_lanczos.webp" height="86" width="150"
           alt="Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/liu-hydraplus-net-2017/" >HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis</a>
    </div>

    
    <a href="/publication/liu-hydraplus-net-2017/"  class="summary-link">
      <div class="article-style">
        Pedestrian analysis plays a vital role in intelligent video surveillance and is a key component for security-centric computer vision …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Xihui Liu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Haiyu Zhao</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Maoqing Tian</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Jing Shao</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Shuai Yi</span>, <span >
      Junjie Yan</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_HydraPlus-Net_Attentive_Deep_ICCV_2017_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/liu-hydraplus-net-2017/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/xh-liu/HydraPlus-Net" target="_blank" rel="noopener">
  Code
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/drive/folders/0B5_Ra3JsEOyOUlhKM0VPZ1ZWR2M?resourcekey=0-CdctEkdX1j2GSMSWWfrPSQ" target="_blank" rel="noopener">
  Dataset
</a>



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://xh-liu.github.io/HydraPlus-Net/" target="_blank" rel="noopener">
  Project
</a>









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ICCV.2017.46" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/liu-hydraplus-net-2017/" >
      <img src="/publication/liu-hydraplus-net-2017/featured_hu8f8c7dbd73805915143748d951ec3b3f_76076_150x0_resize_q75_h2_lanczos_3.webp" height="100" width="150"
           alt="HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sheng-generative-2017/" >A Generative Model for Depth-Based Robust 3D Facial Pose Tracking</a>
    </div>

    
    <a href="/publication/sheng-generative-2017/"  class="summary-link">
      <div class="article-style">
        We consider the problem of depth-based robust 3D facial pose tracking under unconstrained scenarios with heavy occlusions and arbitrary …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Jianfei Cai</span>, <span >
      Tat-Jen Cham</span>, <span >
      Vladimir Pavlovic</span>, <span >
      King Ngi Ngan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Sheng_A_Generative_Model_CVPR_2017_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sheng-generative-2017/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2017.489" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/sheng-generative-2017/" >
      <img src="/publication/sheng-generative-2017/featured_hu0fcdffd010b5226e8ea87e348fee16e8_83762_150x0_resize_q75_h2_lanczos.webp" height="84" width="150"
           alt="A Generative Model for Depth-Based Robust 3D Facial Pose Tracking" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/cheung-disocclusion-2015/" >A disocclusion filling method using multiple sprites with depth for virtual view synthesis</a>
    </div>

    
    <a href="/publication/cheung-disocclusion-2015/"  class="summary-link">
      <div class="article-style">
        Depth image based rendering (DIBR) is an important technique to generate virtual view images with limited 3-D data. However, …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Chi Ho Cheung</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      King Ngi Ngan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/cheung-disocclusion-2015/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ICMEW.2015.7169773" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sheng-accelerating-2015/" >Accelerating the Distribution Estimation for the Weighted Median/Mode Filters</a>
    </div>

    
    <a href="/publication/sheng-accelerating-2015/"  class="summary-link">
      <div class="article-style">
        Various image filters for applications in the area of computer vision require the properties of the local statistics of the input …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Lu Sheng</span>, <span >
      King Ngi Ngan</span>, <span >
      Tak-Wai Hui</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sheng-accelerating-2015/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-319-16817-3_1" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  

  
<nav class="mt-1">
  <ul class="pagination justify-content-center">
    
    <li class="page-item"><a class="page-link" href="/publication-type/1/page/2/">&laquo;</a></li>
    
    
    <li class="page-item"><a class="page-link" href="/publication-type/1/page/4/">&raquo;</a></li>
    
  </ul>
</nav>


</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  

  

  

  
  






  
  <p class="powered-by copyright-license-text">
    © 2022 Lu Sheng. Last updated Aug 30, 2022.
  </p>
  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.46271ef31da3f018e9cd1b59300aa265.js"></script>




  

  
  

  






























<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js" type="module"></script>









<script src="/en/js/wowchemy.min.6ae253cfe39dce6eae1aa243112736e8.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>
















</body>
</html>
