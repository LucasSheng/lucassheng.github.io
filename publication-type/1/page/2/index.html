<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.6.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Lu Sheng" />

  
  
  
    
  
  <meta name="description" content="Associate Professor" />

  
  <link rel="alternate" hreflang="en-us" href="https://lucassheng.github.io/publication-type/1/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.e16b071c3437dd38fe4bc6049c3c2fff.css" />

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



  


  


  




  
  
  

  
  
    <link rel="alternate" href="/publication-type/1/index.xml" type="application/rss+xml" title="Lu Sheng (盛律)" />
  

  
  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://lucassheng.github.io/publication-type/1/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Lu Sheng (盛律)" />
  <meta property="og:url" content="https://lucassheng.github.io/publication-type/1/" />
  <meta property="og:title" content="1 | Lu Sheng (盛律)" />
  <meta property="og:description" content="Associate Professor" /><meta property="og:image" content="https://lucassheng.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://lucassheng.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="og:updated_time" content="2022-10-23T00:00:00&#43;00:00" />
    
  

  



  


  <title>1 | Lu Sheng (盛律)</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.613040fe4f2c0f007b4dcb64404201cb.js"></script>

  




  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Lu Sheng (盛律)</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Lu Sheng (盛律)</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#news"><span>News</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    












  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>1</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/yang-increaco-2021/" >IncreACO: Incrementally Learned Automatic Check-out with Photorealistic Exemplar Augmentation</a>
    </div>

    
    <a href="/publication/yang-increaco-2021/"  class="summary-link">
      <div class="article-style">
        Automatic check-out (ACO) emerges as an integral component in recent self-service retailing stores, which aims at automatically …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Yandan Yang</span>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Xiaolong Jiang</span>, <span >
      Haochen Wang</span>, <span >
      Dong Xu</span>, <span >
      Xianbin Cao</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/yang-increaco-2021/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/WACV48630.2021.00067" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/document/9423423/" target="_blank" rel="noopener">
    URL</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/yang-increaco-2021/" >
      <img src="/publication/yang-increaco-2021/featured_hu25a11d0ec0578d09411f184b625c8a92_161833_150x0_resize_q75_h2_lanczos_3.webp" height="75" width="150"
           alt="IncreACO: Incrementally Learned Automatic Check-out with Photorealistic Exemplar Augmentation" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/vedaldi-powering-2020/" >Powering One-Shot Topological NAS with Stabilized Share-Parameter Proxy</a>
    </div>

    
    <a href="/publication/vedaldi-powering-2020/"  class="summary-link">
      <div class="article-style">
        One-shot NAS method has attracted much interest from the research community due to its remarkable training eﬃciency and capacity to …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Ronghao Guo</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Chen Lin</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Chuming Li</span>, <span >
      Keyu Tian</span>, <span >
      Ming Sun</span>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Junjie Yan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590613.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/vedaldi-powering-2020/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-030-58568-6_37" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/vedaldi-powering-2020/" >
      <img src="/publication/vedaldi-powering-2020/featured_hua20ed8f2342312feec1edbf37a41587a_74927_150x0_resize_q75_h2_lanczos_3.webp" height="117" width="150"
           alt="Powering One-Shot Topological NAS with Stabilized Share-Parameter Proxy" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/vedaldi-thinking-2020/" >Thinking in Frequency: Face Forgery Detection by Mining Frequency-Aware Clues</a>
    </div>

    
    <a href="/publication/vedaldi-thinking-2020/"  class="summary-link">
      <div class="article-style">
        As realistic facial manipulation technologies have achieved remarkable progress, social concerns about potential malicious abuse of …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Yuyang Qian</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Guojun Yin</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution, Corresponding author"></i>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Zixuan Chen</span>, <span >
      Jing Shao</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570086.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/vedaldi-thinking-2020/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-030-58610-2_6" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/yyk-wew/F3Net" target="_blank" rel="noopener">
    Unofficial implementation</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/vedaldi-thinking-2020/" >
      <img src="/publication/vedaldi-thinking-2020/featured_hu86d170467327c71a709cbd943f58c598_202544_150x0_resize_q75_h2_lanczos_3.webp" height="42" width="150"
           alt="Thinking in Frequency: Face Forgery Detection by Mining Frequency-Aware Clues" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/liu-morphing-2020/" >Morphing and Sampling Network for Dense Point Cloud Completion</a>
    </div>

    
    <a href="/publication/liu-morphing-2020/"  class="summary-link">
      <div class="article-style">
        3D point cloud completion, the task of inferring the complete geometric shape from a partial point cloud, has been attracting attention …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Minghua Liu</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Sheng Yang</span>, <span >
      Jing Shao</span>, <span >
      Shi-Min Hu</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ojs.aaai.org/index.php/AAAI/article/view/6827" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/liu-morphing-2020/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/Colin97/MSN-Point-Cloud-Completion" target="_blank" rel="noopener">
  Code
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/drive/folders/1X143kUwtRtoPFxNRvUk9LuPlsf1lLKI7" target="_blank" rel="noopener">
  Dataset
</a>



  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/image-and-video-synthesis/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1609/aaai.v34i07.6827" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/liu-morphing-2020/" >
      <img src="/publication/liu-morphing-2020/featured_hubb9368b37e2e09ae0091221419686dd1_2010504_150x0_resize_q75_h2_lanczos_3.webp" height="88" width="150"
           alt="Morphing and Sampling Network for Dense Point Cloud Completion" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/wang-camp-2019/" >CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval</a>
    </div>

    
    <a href="/publication/wang-camp-2019/"  class="summary-link">
      <div class="article-style">
        Text-image cross-modal retrieval is a challenging task in the field of language and vision. Most previous approaches independently …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Zihao Wang</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Xihui Liu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Hongsheng Li</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Junjie Yan</span>, <span >
      Xiaogang Wang</span>, <span >
      Jing Shao</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_CAMP_Cross-Modal_Adaptive_Message_Passing_for_Text-Image_Retrieval_ICCV_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/wang-camp-2019/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/ZihaoWang-CV/CAMP_iccv19" target="_blank" rel="noopener">
  Code
</a>












<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ICCV.2019.00586" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/wang-camp-2019/" >
      <img src="/publication/wang-camp-2019/featured_hua046c90be43ce1c0bb3bca964c183e47_321255_150x0_resize_q75_h2_lanczos_3.webp" height="63" width="150"
           alt="CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/tang-improving-2019/" >Improving Pedestrian Attribute Recognition With Weakly-Supervised Multi-Scale Attribute-Specific Localization</a>
    </div>

    
    <a href="/publication/tang-improving-2019/"  class="summary-link">
      <div class="article-style">
        Pedestrian attribute recognition has been an emerging research topic in the area of video surveillance. To predict the existence of a …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Chufeng Tang</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Zhao-Xiang Zhang</span>, <span >
      Xiaolin Hu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Tang_Improving_Pedestrian_Attribute_Recognition_With_Weakly-Supervised_Multi-Scale_Attribute-Specific_Localization_ICCV_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/tang-improving-2019/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/chufengt/ALM-pedestrian-attribute" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://chufengt.github.io/publication/pedestrian-attribute/iccv_poster_id2029.pdf" target="_blank" rel="noopener">
  Poster
</a>







<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ICCV.2019.00510" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/tang-improving-2019/" >
      <img src="/publication/tang-improving-2019/featured_hu85f4366d7e212343729896f6a319a3e0_218744_150x0_resize_q75_h2_lanczos_3.webp" height="70" width="150"
           alt="Improving Pedestrian Attribute Recognition With Weakly-Supervised Multi-Scale Attribute-Specific Localization" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/sheng-unsupervised-2019/" >Unsupervised Collaborative Learning of Keyframe Detection and Visual Odometry Towards Monocular Deep SLAM</a>
    </div>

    
    <a href="/publication/sheng-unsupervised-2019/"  class="summary-link">
      <div class="article-style">
        In this paper we tackle the joint learning problem of keyframe detection and visual odometry towards monocular visual SLAM systems. As …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Dan Xu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Wanli Ouyang</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Sheng_Unsupervised_Collaborative_Learning_of_Keyframe_Detection_and_Visual_Odometry_Towards_ICCV_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sheng-unsupervised-2019/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ICCV.2019.00440" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/sheng-unsupervised-2019/" >
      <img src="/publication/sheng-unsupervised-2019/featured_huc169a33371988cef23233c7506b1d752_189339_150x0_resize_q75_h2_lanczos_3.webp" height="96" width="150"
           alt="Unsupervised Collaborative Learning of Keyframe Detection and Visual Odometry Towards Monocular Deep SLAM" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/yin-context-2019/" >Context and Attribute Grounded Dense Captioning</a>
    </div>

    
    <a href="/publication/yin-context-2019/"  class="summary-link">
      <div class="article-style">
        Dense captioning aims at simultaneously localizing semantic regions and describing these regions-of-interest (ROIs) with short phrases …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Guojun Yin</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Bin Liu</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Nenghai Yu</span>, <span >
      Xiaogang Wang</span>, <span >
      Jing Shao</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yin_Context_and_Attribute_Grounded_Dense_Captioning_CVPR_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/yin-context-2019/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/gjyin91/CAG-Net" target="_blank" rel="noopener">
  Code
</a>




  
    
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2019.00640" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/yin-context-2019/" >
      <img src="/publication/yin-context-2019/featured_hu5aac2beeffb48e9edb003350eb5f46ab_144707_150x0_resize_q75_h2_lanczos_3.webp" height="80" width="150"
           alt="Context and Attribute Grounded Dense Captioning" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/li-gs-3-d-2019/" >GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving</a>
    </div>

    
    <a href="/publication/li-gs-3-d-2019/"  class="summary-link">
      <div class="article-style">
        We present an efﬁcient 3D object detection framework based on a single RGB image in the scenario of autonomous driving. Our efforts are …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Buyu Li</span>, <span >
      Wanli Ouyang</span>, <span class="author-highlighted">
      Lu Sheng</span>, <span >
      Xingyu Zeng</span>, <span >
      Xiaogang Wang</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_GS3D_An_Efficient_3D_Object_Detection_Framework_for_Autonomous_Driving_CVPR_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/li-gs-3-d-2019/cite.bib">
  Cite
</a>





  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/3d-perception-and-modeling/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2019.00111" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/li-gs-3-d-2019/" >
      <img src="/publication/li-gs-3-d-2019/featured_hufa95f52956de6f1dda8a4171a3713296_200559_150x0_resize_q75_h2_lanczos_3.webp" height="25" width="150"
           alt="GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving" loading="lazy">
    </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/yin-semantics-2019/" >Semantics Disentangling for Text-To-Image Generation</a>
    </div>

    
    <a href="/publication/yin-semantics-2019/"  class="summary-link">
      <div class="article-style">
        Synthesizing photo-realistic images from text descriptions is a challenging problem. Previous studies have shown remarkable progresses …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Guojun Yin</span>, <span >
      Bin Liu</span>, <span class="author-highlighted">
      Lu Sheng</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Corresponding author"></i>, <span >
      Nenghai Yu</span>, <span >
      Xiaogang Wang</span>, <span >
      Jing Shao</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yin_Semantics_Disentangling_for_Text-To-Image_Generation_CVPR_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/yin-semantics-2019/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/gjyin91/SDGAN" target="_blank" rel="noopener">
  Code
</a>




  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/project/image-and-video-synthesis/">
    Project
  </a>
  









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2019.00243" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
    
    <a href="/publication/yin-semantics-2019/" >
      <img src="/publication/yin-semantics-2019/featured_hu997a7cf18c4e3ce080bbfe5f97a33f54_195311_150x0_resize_q75_h2_lanczos_3.webp" height="135" width="150"
           alt="Semantics Disentangling for Text-To-Image Generation" loading="lazy">
    </a>
    
  </div>
</div>

  

  
<nav class="mt-1">
  <ul class="pagination justify-content-center">
    
    <li class="page-item"><a class="page-link" href="/publication-type/1/">&laquo;</a></li>
    
    
    <li class="page-item"><a class="page-link" href="/publication-type/1/page/3/">&raquo;</a></li>
    
  </ul>
</nav>


</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  

  

  

  
  






  
  <p class="powered-by copyright-license-text">
    © 2022 Lu Sheng. Last updated Aug 30, 2022.
  </p>
  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.46271ef31da3f018e9cd1b59300aa265.js"></script>




  

  
  

  






























<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js" type="module"></script>









<script src="/en/js/wowchemy.min.6ae253cfe39dce6eae1aa243112736e8.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>
















</body>
</html>
